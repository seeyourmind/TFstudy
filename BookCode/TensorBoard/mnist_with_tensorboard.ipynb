{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_DATA/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_DATA/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_DATA/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_DATA/t10k-labels-idx1-ubyte.gz\n",
      "After 1 training step(s), loss on training batch is 3.17171\n",
      "After 1001 training step(s), loss on training batch is 0.264185\n",
      "After 2001 training step(s), loss on training batch is 0.167638\n",
      "After 3001 training step(s), loss on training batch is 0.144205\n",
      "After 4001 training step(s), loss on training batch is 0.141952\n",
      "After 5001 training step(s), loss on training batch is 0.103511\n",
      "After 6001 training step(s), loss on training batch is 0.107374\n",
      "After 7001 training step(s), loss on training batch is 0.0870436\n",
      "After 8001 training step(s), loss on training batch is 0.0855941\n",
      "After 9001 training step(s), loss on training batch is 0.0721913\n",
      "After 10001 training step(s), loss on training batch is 0.0671718\n",
      "After 11001 training step(s), loss on training batch is 0.0691625\n",
      "After 12001 training step(s), loss on training batch is 0.0636319\n",
      "After 13001 training step(s), loss on training batch is 0.0651156\n",
      "After 14001 training step(s), loss on training batch is 0.0590771\n",
      "After 15001 training step(s), loss on training batch is 0.0482412\n",
      "After 16001 training step(s), loss on training batch is 0.0498731\n",
      "After 17001 training step(s), loss on training batch is 0.0509046\n",
      "After 18001 training step(s), loss on training batch is 0.0448768\n",
      "After 19001 training step(s), loss on training batch is 0.0419202\n",
      "After 20001 training step(s), loss on training batch is 0.0476828\n",
      "After 21001 training step(s), loss on training batch is 0.0398035\n",
      "After 22001 training step(s), loss on training batch is 0.0415462\n",
      "After 23001 training step(s), loss on training batch is 0.0428534\n",
      "After 24001 training step(s), loss on training batch is 0.0409395\n",
      "After 25001 training step(s), loss on training batch is 0.0334084\n",
      "After 26001 training step(s), loss on training batch is 0.0345411\n",
      "After 27001 training step(s), loss on training batch is 0.0372495\n",
      "After 28001 training step(s), loss on training batch is 0.031926\n",
      "After 29001 training step(s), loss on training batch is 0.0318244\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fyzer/anaconda3/envs/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2870: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "'''\n",
    "本例是使用TensorBoard\n",
    "part2: mnist_train.py\n",
    "主要用来训练神经网络，并将测试与验证数据分离\n",
    "'''\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import mnist_inference\n",
    "\n",
    "import time\n",
    "\n",
    "# 配置神经网络参数\n",
    "BATCH_SIZE = 100\n",
    "LEARNING_RATE_BASE = 0.8\n",
    "LEARNING_RATE_DECAY = 0.99\n",
    "REGULARIZATION_RATE = 0.0001\n",
    "TRAINING_STEPS = 30000\n",
    "MOVING_AVERAGE_DECAY = 0.99\n",
    "# 模型保存的路径和文件名\n",
    "MODEL_SAVE_PATH = 'MNIST_MODEL'\n",
    "MODEL_NAME = 'model.ckpt'\n",
    "\n",
    "'''\n",
    "训练模型\n",
    "'''\n",
    "def train(mnist):\n",
    "    # 定义输入输出的placeholder\n",
    "    # 将处理输入数据的计算都放在名字input的命名空间\n",
    "    with tf.name_scope('input'):\n",
    "        x = tf.placeholder(tf.float32, [None, mnist_inference.INPUT_NODE], name='x-input')\n",
    "        y_ = tf.placeholder(tf.float32, [None, mnist_inference.OUTPUT_NODE], name='y-input')\n",
    "    \n",
    "    # 定义L2正则化损失函数\n",
    "    regularizer = tf.contrib.layers.l2_regularizer(REGULARIZATION_RATE) \n",
    "    # 前向传播\n",
    "    y = mnist_inference.inference(x, None, regularizer)\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    \n",
    "    # 带滑动平均模型的前向传播\n",
    "    # 将处理滑动平均相关的计算都放在moving_average的命名空间\n",
    "    with tf.name_scope('moving_average'):\n",
    "        variable_averages = tf.train.ExponentialMovingAverage(decay=MOVING_AVERAGE_DECAY, num_updates=global_step)\n",
    "        variables_averages_op = variable_averages.apply(tf.trainable_variables())\n",
    "    #average_y = mnist_inference.inference(x, variable_averages, regularizer)\n",
    "    \n",
    "    # 计算损失函数\n",
    "    # 将计算损失函数放在loss_function的命名空间\n",
    "    with tf.name_scope('loss_function'):\n",
    "        cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=tf.argmax(y_,1), logits=y)\n",
    "        cross_entropy_mean = tf.reduce_mean(cross_entropy)\n",
    "        loss = cross_entropy_mean+tf.add_n(tf.get_collection('losses'))\n",
    "    \n",
    "    # 反向传播\n",
    "    # 将定义学习率、优化方法及训练操作都放在train_step的命名空间\n",
    "    with tf.name_scope('train_step'):\n",
    "        # 设置指数衰减的学习率\n",
    "        learning_rate = tf.train.exponential_decay(LEARNING_RATE_BASE, global_step, mnist.train.num_examples/BATCH_SIZE, LEARNING_RATE_DECAY)\n",
    "        # 定义优化损失函数\n",
    "        train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "    \n",
    "        # 更新参数[不带滑动平均]\n",
    "        # 下面的语句将无效，然后在sess.run中，改为：\n",
    "        # sess.run(train_step, feed_dict={x:xs, y_:ys})\n",
    "        # 更新参数[反向传播+滑动平均]\n",
    "        with tf.control_dependencies([train_step, variables_averages_op]):\n",
    "            train_op = tf.no_op(name='train')# 什么也不做\n",
    "    \n",
    "        # 初始化Tensorflow持久化类\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        # 将当前的计算图输出到TensorBoard日志文件\n",
    "        writer = tf.summary.FileWriter('log/'+str(int(time.time())), tf.get_default_graph())\n",
    "    \n",
    "        # 初始化会话并开始训练\n",
    "        with tf.Session() as sess:\n",
    "            # 初始化所有变量\n",
    "            tf.global_variables_initializer().run()\n",
    "        \n",
    "            # 迭代训练神经网络\n",
    "            for i in range(TRAINING_STEPS):\n",
    "                # 产生本轮batch的训练数据，并运行训练程序\n",
    "                xs, ys = mnist.train.next_batch(BATCH_SIZE)\n",
    "                \n",
    "                # 每1000轮保存一次模型\n",
    "                # 记录运行状态\n",
    "                if i%1000 == 0:\n",
    "                    # 配置运行时需要记录的信息\n",
    "                    run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n",
    "                    # 运行时记录运行信息的proto\n",
    "                    run_metadata = tf.RunMetadata()\n",
    "                    # 将以上两个参数传入sess.run完成信息的记录\n",
    "                    _, loss_value, step = sess.run([train_op, loss, global_step], feed_dict={x:xs, y_:ys}, options=run_options, run_metadata=run_metadata)\n",
    "                    # 将节点信息写入日志文件\n",
    "                    writer.add_run_metadata(run_metadata, 'step%03d'%i)\n",
    "                    # 通过损失函数的大小了解本轮训练的基本情况\n",
    "                    print(\"After %d training step(s), loss on training batch is %g\"%(step, loss_value))\n",
    "                    # 保存模型，给出global_step参数可以让每个被保存的文件名末尾加上训练的轮数\n",
    "                    saver.save(sess, os.path.join(MODEL_SAVE_PATH, MODEL_NAME), global_step=global_step)\n",
    "                else:\n",
    "                    _, loss_value, step = sess.run([train_op, loss, global_step], feed_dict={x:xs, y_:ys})\n",
    "    \n",
    "        writer.close()\n",
    "    \n",
    "# 主程序入口\n",
    "def main(argv=None):\n",
    "    # 如果指定路径下没有数据，则自动下载\n",
    "    mnist = input_data.read_data_sets(\"MNIST_DATA\", one_hot=True)\n",
    "    train(mnist)\n",
    "# TensorFlow提供的一个主程序入口\n",
    "if __name__ == '__main__':\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
