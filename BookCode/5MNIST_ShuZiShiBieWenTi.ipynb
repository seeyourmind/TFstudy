{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_DATA/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_DATA/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_DATA/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_DATA/t10k-labels-idx1-ubyte.gz\n",
      "After 0 training step(s), validation accuracy using average model is 0.0828\n",
      "After 1000 training step(s), validation accuracy using average model is 0.9754\n",
      "After 2000 training step(s), validation accuracy using average model is 0.9816\n",
      "After 3000 training step(s), validation accuracy using average model is 0.9832\n",
      "After 4000 training step(s), validation accuracy using average model is 0.983\n",
      "After 5000 training step(s), validation accuracy using average model is 0.984\n",
      "After 6000 training step(s), validation accuracy using average model is 0.983\n",
      "After 7000 training step(s), validation accuracy using average model is 0.984\n",
      "After 8000 training step(s), validation accuracy using average model is 0.9836\n",
      "After 9000 training step(s), validation accuracy using average model is 0.9838\n",
      "After 10000 training step(s), validation accuracy using average model is 0.9838\n",
      "After 11000 training step(s), validation accuracy using average model is 0.984\n",
      "After 12000 training step(s), validation accuracy using average model is 0.9842\n",
      "After 13000 training step(s), validation accuracy using average model is 0.984\n",
      "After 14000 training step(s), validation accuracy using average model is 0.9838\n",
      "After 15000 training step(s), validation accuracy using average model is 0.9844\n",
      "After 16000 training step(s), validation accuracy using average model is 0.985\n",
      "After 17000 training step(s), validation accuracy using average model is 0.9842\n",
      "After 18000 training step(s), validation accuracy using average model is 0.9844\n",
      "After 19000 training step(s), validation accuracy using average model is 0.9836\n",
      "After 20000 training step(s), validation accuracy using average model is 0.9838\n",
      "After 21000 training step(s), validation accuracy using average model is 0.9838\n",
      "After 22000 training step(s), validation accuracy using average model is 0.9848\n",
      "After 23000 training step(s), validation accuracy using average model is 0.9844\n",
      "After 24000 training step(s), validation accuracy using average model is 0.9848\n",
      "After 25000 training step(s), validation accuracy using average model is 0.9844\n",
      "After 26000 training step(s), validation accuracy using average model is 0.9846\n",
      "After 27000 training step(s), validation accuracy using average model is 0.9844\n",
      "After 28000 training step(s), validation accuracy using average model is 0.9842\n",
      "After 29000 training step(s), validation accuracy using average model is 0.9842\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'TREANING_STEPS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-fcaf98a3229c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;31m# tf.app.run()会调用上面的main()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/platform/app.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m     46\u001b[0m   \u001b[0;31m# Call the main function, passing through any arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[0;31m# to the final program.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m   \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mflags_passthrough\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-fcaf98a3229c>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(argv)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;31m# 如果指定路径下没有数据，则自动下载\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0mmnist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_data_sets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MNIST_DATA\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;31m# TensorFlow提供的一个主程序入口\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-fcaf98a3229c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(mnist)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;31m# 训练结束，显示最终正确率\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_feed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"After %d training step(s), test accuracy using average model is %g\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTREANING_STEPS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;31m# 主程序入口\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TREANING_STEPS' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# MNIST数据集相关常数\n",
    "INPUT_NODE = 784\n",
    "OUTPUT_NODE = 10\n",
    "\n",
    "# 配置神经网络参数\n",
    "LAYER1_NODE = 500\n",
    "BATCH_SIZE = 100\n",
    "LEARNING_RATE_BASE = 0.8\n",
    "LEARNING_RATE_DECAY = 0.99\n",
    "REGULARIZATION_RATE = 0.0001\n",
    "TRAINING_STEPS = 30000\n",
    "MOVING_AVERAGE_DECAY = 0.99\n",
    "\n",
    "# 辅助函数:计算神经网络前向传播结果\n",
    "# layer1为隐藏层，实现三层结构\n",
    "# 使用ReLu激活函数去线性化\n",
    "# 支持滑动平均模型计算变量\n",
    "def inference(input_tensor, avg_class, weights1, biases1, weights2, biases2):\n",
    "    if avg_class == None:\n",
    "        layer1 = tf.nn.relu(tf.matmul(input_tensor, weights1)+biases1)\n",
    "        return tf.matmul(layer1, weights2)+biases2\n",
    "    else:\n",
    "        layer1 = tf.nn.relu(tf.matmul(input_tensor, avg_class.average(weights1))+avg_class.average(biases1))\n",
    "        return tf.matmul(layer1, avg_class.average(weights2))+avg_class.average(biases2)\n",
    "\n",
    "# 训练模型\n",
    "def train(mnist):\n",
    "    x = tf.placeholder(tf.float32, [None, INPUT_NODE], name='x-input')\n",
    "    y_ = tf.placeholder(tf.float32, [None, OUTPUT_NODE], name='y-input')\n",
    "    \n",
    "    '''\n",
    "    生成权重与偏移量\n",
    "    '''\n",
    "    # 生成隐藏层参数\n",
    "    weights1 = tf.Variable(tf.truncated_normal([INPUT_NODE, LAYER1_NODE], stddev=0.1))\n",
    "    biases1 = tf.Variable(tf.constant(0.1, shape=[LAYER1_NODE]))\n",
    "    # 生成输出层参数\n",
    "    weights2 = tf.Variable(tf.truncated_normal([LAYER1_NODE, OUTPUT_NODE], stddev=0.1))\n",
    "    biases2 = tf.Variable(tf.constant(0.1, shape=[OUTPUT_NODE]))\n",
    "    \n",
    "    '''\n",
    "    前向传播\n",
    "    '''\n",
    "    # 无滑动平均的前向传播\n",
    "    y = inference(x, None, weights1, biases1, weights2, biases2)\n",
    "    # 定义训练轮数\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    # 初始化滑动平均模型\n",
    "    # 给定训练轮数可以加快训练早期变量的更新速度\n",
    "    variable_averages = tf.train.ExponentialMovingAverage(decay=MOVING_AVERAGE_DECAY, num_updates=global_step)\n",
    "    # 定义滑动平均模型更新操作\n",
    "    # trainable_variables()函数获取所有神经网络中可训练的变量\n",
    "    variables_averages_op = variable_averages.apply(tf.trainable_variables())\n",
    "    # 带滑动平均的前向传播\n",
    "    average_y = inference(x, variable_averages, weights1, biases1, weights2, biases2)\n",
    "    \n",
    "    '''\n",
    "    损失函数\n",
    "    '''\n",
    "    # 计算损失函数\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=tf.argmax(y_,1), logits=y)#labels神经网络期望的输出，logits神经网络最后一层的输入即softmax层\n",
    "    # 计算当前batch中所有样例的交叉熵平均值\n",
    "    cross_entropy_mean = tf.reduce_mean(cross_entropy)\n",
    "    # 定义L2正则化损失函数\n",
    "    regularizer = tf.contrib.layers.l2_regularizer(REGULARIZATION_RATE)\n",
    "    # 计算模型的正则化损失\n",
    "    regularization = regularizer(weights1)+regularizer(weights2)\n",
    "    # 最终的总损失函数\n",
    "    loss = cross_entropy_mean+regularization\n",
    "    \n",
    "    '''\n",
    "    反向传播\n",
    "    '''\n",
    "    # 设置指数衰减的学习率\n",
    "    # global_step当前迭代的轮数\n",
    "    # mnist.train.num_examples/BATCH_SIZE过完所有训练数据需要的迭代次数\n",
    "    learning_rate = tf.train.exponential_decay(LEARNING_RATE_BASE, global_step, mnist.train.num_examples/BATCH_SIZE, LEARNING_RATE_DECAY)\n",
    "    # 定义优化损失函数\n",
    "    train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "    \n",
    "    '''\n",
    "    1、依据反向传播更新神经网络参数\n",
    "    2、更新每一个参数的滑动平均值\n",
    "    '''\n",
    "    # 更新参数[反向传播+滑动平均]\n",
    "    # Tensorflow提供两种机制tf.control_dependencies和tf.group\n",
    "    with tf.control_dependencies([train_step, variables_averages_op]):\n",
    "        train_op = tf.no_op(name='train')\n",
    "    # 等价于\n",
    "    # train_op = tf.group(train_step, variables_averages_op)\n",
    "    \n",
    "    '''\n",
    "    检验使用滑动平均模型的神经网络前向传播结果是否正确\n",
    "    '''\n",
    "    # 计算模型预测精度\n",
    "    # tf.argmax()函数返回最大值的下标\n",
    "    # tf.equal()函数比较两个张量是否相等\n",
    "    correct_prediction = tf.equal(tf.argmax(average_y, 1), tf.argmax(y_,1))\n",
    "    # 将比尔型转化为float32并求平均值，即得一组数据的正确率\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    # 初始化会话并开始训练\n",
    "    with tf.Session() as sess:\n",
    "        # 初始化所有变量\n",
    "        tf.global_variables_initializer().run()\n",
    "        # 准备验证数据\n",
    "        validate_feed = {x:mnist.validation.images, y_:mnist.validation.labels}\n",
    "        # 准备测试数据\n",
    "        test_feed = {x:mnist.test.images, y_:mnist.test.labels}\n",
    "    \n",
    "        # 迭代训练神经网络\n",
    "        for i in range(TRAINING_STEPS):\n",
    "            if i%1000 == 0:\n",
    "                validate_acc = sess.run(accuracy, feed_dict=validate_feed)\n",
    "                print(\"After %d training step(s), validation accuracy using average model is %g\"%(i, validate_acc))\n",
    "            \n",
    "            # 产生本轮batch的训练数据，并运行训练程序\n",
    "            xs, ys = mnist.train.next_batch(BATCH_SIZE)\n",
    "            sess.run(train_op, feed_dict={x:xs, y_:ys})\n",
    "    \n",
    "        # 训练结束，显示最终正确率\n",
    "        test_acc = sess.run(accuracy, feed_dict=test_feed)\n",
    "        print(\"After %d training step(s), test accuracy using average model is %g\"%(TRAINING_STEPS, test_acc))\n",
    "    \n",
    "# 主程序入口\n",
    "def main(argv=None):\n",
    "    # 如果指定路径下没有数据，则自动下载\n",
    "    mnist = input_data.read_data_sets(\"MNIST_DATA\", one_hot=True)\n",
    "    train(mnist)\n",
    "\n",
    "# TensorFlow提供的一个主程序入口\n",
    "# tf.app.run()会调用上面的main()\n",
    "if __name__ == '__main__':\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
